\documentclass{article}
\usepackage[utf8]{inputenc}    % For UTF-8 character encoding
\usepackage[T1]{fontenc}       % For proper font encoding
\usepackage{lmodern}           % Improved font rendering
\usepackage{amsmath}   % For advanced mathematical formatting
\usepackage{amssymb}   % For mathematical symbols
\usepackage{geometry}  % Adjust page margins
\usepackage{enumerate} % For custom lists
\usepackage{xcolor}  % for coloring
\usepackage{amsthm}
\usepackage{pdfpages}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\usepackage{listings}  % for code listings

\lstset{frame=tb,
  language=C,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,   
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{brown},
  stringstyle=\color{orange},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\geometry{top=1in, bottom=1in, left=1in, right=1in}

\begin{document}

\title{}
\author{Wang Xiyu}
\date{}
\maketitle
\section{Overview}
\begin{itemize}
    \item Week 1-3: Classical AI, search algorithms
        \begin{enumerate} 
            \item Uninformed search
            \item Local search: hill climbing
            \item Informaed search: A$^*$
            \item Adversarial search Minimax
        \end{enumerate}
    \item Week 4-7: Classical ML
        \begin{enumerate}
            \item Decision trees 
            \item Linear/Logistic regression 
            \item Kernels and support vector machines
            \item "Classical" unsuperivese learning
        \end{enumerate}
    \item Week 10-12: Modern ML
        \begin{enumerate}
            \item Neural networks
            \item Deep learning 
            \item Sequential data
        \end{enumerate}
    \item Week 13: Misc.
\end{itemize}

\section{AI: Computers Trying to Behave Like Humans}

\begin{itemize}
    \item \textbf{PEAS Framework:}
    \begin{itemize}
        \item \textbf{Performance measure:} define “goodness” of a solution
        \item \textbf{Environment:} define what the agent can and cannot do
        \item \textbf{Actuators:} outputs
        \item \textbf{Sensors:} inputs
    \end{itemize}
    
    \item Agent function is sufficient.
    
    \item Common agent structures (to define an AI agent):
    \begin{itemize}
        \item Reflex
        \item Goal-based
        \item Utility-based
        \item Learning
        \item (Others possible; can mix and match!)
    \end{itemize}
    
    \item Exploration vs exploitation
\end{itemize}
\section{Problem Statement}
fully observable $\land$ deterministic $\land$ static $\land$ discrete $\implies$ only need to observe once \newline
To solve a prob using search: 
\begin{itemize}
    \item A goal or a set of goals
    \item a model of the enironment  
    \item a search algorithm 
\end{itemize}

goal formulation -> problem formulation -> search -> execute \newline
\begin{enumerate}
    \item goal formulation
    \item problem formulation, eg. path finding 
        \begin{itemize}
            \item states: nodes representation invariant:: abstract states should correspond to concrete states
            \item initial state: starting node
            \item goal states/test: dest node \newline
                Goal test: define the goal using a function $is\_goal $
            \item actions: move along an edge :: $|actions(state)| \leq branching\_factor$
            \item transition model: 
                $f(curr\_state, action) \implies next\_state $
            \item action cost function: see edges
        \end{itemize}
    \item Important facts:
        \begin{itemize}
            \item Representation Invariant: ensure that the abstract states correspond to concrete states
            \item Goal Test: Goal defined via a function $is\_goal$
            \item Action: a set of $action(state)$, $|actions(state)| \leq branching\_factor$
            \item Transition model: $f(curr\_state, action) \implies next\_state $
        \end{itemize}
\end{enumerate}



\section*{Search}

\subsection*{Uninformed search} 
No information that could guide the seaech: no clue how good a state is
\begin{lstlisting}
    create frontier 
    // create visited // with vsited memory
    insert Node(initial_state) to frontier 
    while frontier is not empty: 
        node = frontier.pop() 
        if node.state is goal: 
            return solution 
    //  if node.state in visited: // with vsited memory
    //     continue 
    //  visited.add(state)
        for action in actions(node.state): 
        next_state = transition(node.state, action) 
        frontier.add(Node(next_state)) 
    return failure
\end{lstlisting}
Different subvariant of tree search uses differen DS for the frontier.\newline
\begin{tabular}{|l|l|l|}
    \hline
    \textbf{Search Type} & \textbf{Data Structure for Frontier}\\
    \hline
    BFS & Queue \\
    \hline
    DFS & Stack \\
    \hline
    UCS (Uniform-cost Search) & Priority Queue \\
    \hline
\end{tabular}

    
\subsection*{Depth limited search} 
limit the search to depth l \newline
backtrack when the limit is hit. \newline
time complexity: exponential to search depth \newline
space complexity: size of the frontier \newline
\begin{lstlisting}
    create frontier 
    tier = 0
    insert Node(initial_state) to frontier 
    while (!empty(frontier)) &&  (tier <= limit):
        node = frontier.pop() 
        tier++
        if node.state is goal: 
            return solution 
        for action in actions(node.state): 
        next_state = transition(node.state, action) 
        frontier.add(Node(next_state)) 
    return failure
\end{lstlisting}
\subsection*{Iterative deeptening search} 
search with depth from 0 to inf \newline
return soln when found. Both complete 
\begin{lstlisting}
    create frontier 
    tier = 0
    insert Node(initial_state) to frontier 
    while (!empty(frontier)) && (tier <= limit):
        node = frontier.pop() 
        tier++
        if node.state is goal: 
            return solution 
        for action in actions(node.state): 
        next_state = transition(node.state, action) 
        frontier.add(Node(next_state)) 
    return failure
\end{lstlisting}
\subsection*{Summary} 
\begin{tabular}{|l|l|l|l|l|l|}
    \hline
    \textbf{Name}                  & \textbf{Time Complexity*} & \textbf{Space Complexity*} & \textbf{Complete?} & \textbf{Optimal?} \\
    \hline
    Breadth-first Search           & Exponential               & Exponential                 & Yes                & Yes              \\
    \hline
    Uniform-cost Search            & Exponential               & Exponential                 & Yes                & Yes              \\
    \hline
    Depth-first Search             & Exponential               & Polynomial                  & No\#                 & No           \\
    \hline
    Depth-limited Search           & Exponential               & Polynomial**                & No**               & No**           \\
    \hline
    Iterative Deepening Search     & Exponential               & Exponential**               & Yes                & Yes              \\
    \hline
\end{tabular}
\newline
\# Not complete if not tracking visited nodes, search may stuck in loop before visiting all nodes. \newline
* In terms of some notion of depth/tier \newline
** If used with DFS

\end{document}
